# Generated by Django 5.2.4 on 2025-07-31 13:38

import django.core.validators
import django.db.models.deletion
import simple_history.models
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='Bot',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(help_text='Enter the name of the bot.', max_length=100)),
                ('context', models.TextField(help_text="Provide the bot's main prompt or description of its purpose.")),
                ('max_token', models.IntegerField(default=2048, validators=[django.core.validators.MinValueValidator(1)])),
                ('bot_temperature', models.FloatField(default=0, help_text='Set the temperature for controlling response randomness (0-1). Lower values produce more deterministic responses.')),
                ('top_k', models.IntegerField(default=2, help_text="Set the top-k value for the bot's response selection. This defines how many top options to consider for each response.", validators=[django.core.validators.MinValueValidator(1)])),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('provider', models.CharField(choices=[('bedrock', 'BEDROCK'), ('bedrock/converse', 'BEDROCK_CONVERSE'), ('openai', 'OPENAI')], default='openai', help_text='Select the LLM provider (BEDROCK, BEDROCK_CONVERSE, or OPENAI)', max_length=100)),
                ('provider_keys', models.TextField(blank=True, default='', help_text='API keys or credentials for the selected LLM provider.', max_length=1000)),
                ('llm_model', models.CharField(choices=[('gpt-4', 'GPT4'), ('gpt-4-1106-preview', 'GPT4-128k'), ('gpt-4-turbo', 'GPT4_TURBO'), ('gpt-4o', 'GPT4_O'), ('gpt-4o-mini', 'GPT4_O_MINI'), ('gpt-4.1', 'GPT4_1'), ('gpt-4.1-mini', 'GPT4_1_MINI'), ('o1', 'O1'), ('o1-preview', 'O1 Preview'), ('o1-mini', 'O1 Mini'), ('o3', 'O3'), ('o3-mini', 'O3_MINI')], default='gpt-4o-mini', help_text='Select the LLM model to be used by the bot (e.g., GPT-4o, GPT-4).', max_length=100)),
                ('filter_score', models.FloatField(default=0.8, help_text='Set the filter score for bot response selection (0-1). Responses below this score will be filtered out.')),
                ('end_context', models.TextField(blank=True, help_text='Provide additional prompt or context to append at the end of the main prompt to guide the conversation', null=True)),
                ('introductory_message', models.CharField(blank=True, help_text='Provide an introductory message that the bot will present when the conversation starts.', max_length=1000, null=True)),
                ('abrupt_introductory_message', models.CharField(blank=True, max_length=1000, null=True)),
                ('tag_context', models.TextField(blank=True, help_text='Provide any information or context related to variables (like Python-bound variables) that will be inserted into the prompt.', null=True)),
                ('route', models.CharField(default='/', help_text='Specify the route or API endpoint for interacting with the bot.', max_length=100)),
                ('bot_type', models.CharField(choices=[('SIMPLE', 'SIMPLE'), ('STATE_MACHINE', 'STATE_MACHINE'), ('DATABASE_SIMPLE', 'DATABASE_SIMPLE'), ('INTERVIEW_STATE_MACHINE', 'INTERVIEW_STATE_MACHINE')], default='SIMPLE', max_length=30)),
                ('llm_key', models.CharField(blank=True, max_length=255, null=True)),
                ('dynamic_context', models.TextField(blank=True, help_text="Provide dynamic context that can be adjusted during the bot's interactions, such as personalized data.", null=True)),
                ('dynamic_context_type', models.CharField(blank=True, choices=[('SQL_QUERY', 'SQL_QUERY'), ('PYTHON_SCRIPT', 'PYTHON_SCRIPT')], max_length=20, null=True)),
                ('pre_context', models.TextField(blank=True, help_text='Provide pre-context that will be set before the main prompt to shape the conversation.', null=True)),
                ('tool_context', models.TextField(blank=True, null=True)),
                ('connect_timeout', models.FloatField(default=5.0, help_text='Timeout in seconds for establishing a LLM connection.')),
                ('read_timeout', models.FloatField(default=10.0, help_text='Timeout in seconds for reading a LLM response.')),
            ],
        ),
        migrations.CreateModel(
            name='HistoricalBot',
            fields=[
                ('id', models.BigIntegerField(auto_created=True, blank=True, db_index=True, verbose_name='ID')),
                ('name', models.CharField(help_text='Enter the name of the bot.', max_length=100)),
                ('context', models.TextField(help_text="Provide the bot's main prompt or description of its purpose.")),
                ('max_token', models.IntegerField(default=2048, validators=[django.core.validators.MinValueValidator(1)])),
                ('bot_temperature', models.FloatField(default=0, help_text='Set the temperature for controlling response randomness (0-1). Lower values produce more deterministic responses.')),
                ('top_k', models.IntegerField(default=2, help_text="Set the top-k value for the bot's response selection. This defines how many top options to consider for each response.", validators=[django.core.validators.MinValueValidator(1)])),
                ('created_at', models.DateTimeField(blank=True, editable=False)),
                ('updated_at', models.DateTimeField(blank=True, editable=False)),
                ('provider', models.CharField(choices=[('bedrock', 'BEDROCK'), ('bedrock/converse', 'BEDROCK_CONVERSE'), ('openai', 'OPENAI')], default='openai', help_text='Select the LLM provider (BEDROCK, BEDROCK_CONVERSE, or OPENAI)', max_length=100)),
                ('provider_keys', models.TextField(blank=True, default='', help_text='API keys or credentials for the selected LLM provider.', max_length=1000)),
                ('llm_model', models.CharField(choices=[('gpt-4', 'GPT4'), ('gpt-4-1106-preview', 'GPT4-128k'), ('gpt-4-turbo', 'GPT4_TURBO'), ('gpt-4o', 'GPT4_O'), ('gpt-4o-mini', 'GPT4_O_MINI'), ('gpt-4.1', 'GPT4_1'), ('gpt-4.1-mini', 'GPT4_1_MINI'), ('o1', 'O1'), ('o1-preview', 'O1 Preview'), ('o1-mini', 'O1 Mini'), ('o3', 'O3'), ('o3-mini', 'O3_MINI')], default='gpt-4o-mini', help_text='Select the LLM model to be used by the bot (e.g., GPT-4o, GPT-4).', max_length=100)),
                ('filter_score', models.FloatField(default=0.8, help_text='Set the filter score for bot response selection (0-1). Responses below this score will be filtered out.')),
                ('end_context', models.TextField(blank=True, help_text='Provide additional prompt or context to append at the end of the main prompt to guide the conversation', null=True)),
                ('introductory_message', models.CharField(blank=True, help_text='Provide an introductory message that the bot will present when the conversation starts.', max_length=1000, null=True)),
                ('abrupt_introductory_message', models.CharField(blank=True, max_length=1000, null=True)),
                ('tag_context', models.TextField(blank=True, help_text='Provide any information or context related to variables (like Python-bound variables) that will be inserted into the prompt.', null=True)),
                ('route', models.CharField(default='/', help_text='Specify the route or API endpoint for interacting with the bot.', max_length=100)),
                ('bot_type', models.CharField(choices=[('SIMPLE', 'SIMPLE'), ('STATE_MACHINE', 'STATE_MACHINE'), ('DATABASE_SIMPLE', 'DATABASE_SIMPLE'), ('INTERVIEW_STATE_MACHINE', 'INTERVIEW_STATE_MACHINE')], default='SIMPLE', max_length=30)),
                ('llm_key', models.CharField(blank=True, max_length=255, null=True)),
                ('dynamic_context', models.TextField(blank=True, help_text="Provide dynamic context that can be adjusted during the bot's interactions, such as personalized data.", null=True)),
                ('dynamic_context_type', models.CharField(blank=True, choices=[('SQL_QUERY', 'SQL_QUERY'), ('PYTHON_SCRIPT', 'PYTHON_SCRIPT')], max_length=20, null=True)),
                ('pre_context', models.TextField(blank=True, help_text='Provide pre-context that will be set before the main prompt to shape the conversation.', null=True)),
                ('tool_context', models.TextField(blank=True, null=True)),
                ('connect_timeout', models.FloatField(default=5.0, help_text='Timeout in seconds for establishing a LLM connection.')),
                ('read_timeout', models.FloatField(default=10.0, help_text='Timeout in seconds for reading a LLM response.')),
                ('history_id', models.AutoField(primary_key=True, serialize=False)),
                ('history_date', models.DateTimeField(db_index=True)),
                ('history_change_reason', models.CharField(max_length=100, null=True)),
                ('history_type', models.CharField(choices=[('+', 'Created'), ('~', 'Changed'), ('-', 'Deleted')], max_length=1)),
                ('history_user', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='+', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'verbose_name': 'historical bot',
                'verbose_name_plural': 'historical bots',
                'ordering': ('-history_date', '-history_id'),
                'get_latest_by': ('history_date', 'history_id'),
            },
            bases=(simple_history.models.HistoricalChanges, models.Model),
        ),
        migrations.CreateModel(
            name='HistoricalProfile',
            fields=[
                ('id', models.BigIntegerField(auto_created=True, blank=True, db_index=True, verbose_name='ID')),
                ('first_name', models.CharField(blank=True, max_length=100, null=True)),
                ('email', models.EmailField(max_length=1000)),
                ('phone', models.CharField(blank=True, max_length=20, null=True)),
                ('password', models.CharField(blank=True, max_length=1000, null=True)),
                ('profile_type', models.CharField(choices=[('USER', 'USER'), ('MODERATOR', 'MODERATOR'), ('PROSPECT', 'PROSPECT')], default='USER', max_length=20)),
                ('other_params', models.JSONField(blank=True, null=True)),
                ('created_at', models.DateTimeField(blank=True, editable=False)),
                ('history_id', models.AutoField(primary_key=True, serialize=False)),
                ('history_date', models.DateTimeField(db_index=True)),
                ('history_change_reason', models.CharField(max_length=100, null=True)),
                ('history_type', models.CharField(choices=[('+', 'Created'), ('~', 'Changed'), ('-', 'Deleted')], max_length=1)),
                ('history_user', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='+', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'verbose_name': 'historical profile',
                'verbose_name_plural': 'historical profiles',
                'ordering': ('-history_date', '-history_id'),
                'get_latest_by': ('history_date', 'history_id'),
            },
            bases=(simple_history.models.HistoricalChanges, models.Model),
        ),
        migrations.CreateModel(
            name='Profile',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('first_name', models.CharField(blank=True, max_length=100, null=True)),
                ('email', models.EmailField(max_length=1000)),
                ('phone', models.CharField(blank=True, max_length=20, null=True)),
                ('password', models.CharField(blank=True, max_length=1000, null=True)),
                ('profile_type', models.CharField(choices=[('USER', 'USER'), ('MODERATOR', 'MODERATOR'), ('PROSPECT', 'PROSPECT')], default='USER', max_length=20)),
                ('other_params', models.JSONField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
            options={
                'indexes': [models.Index(fields=['email'], name='chatbot_pro_email_540b78_idx'), models.Index(fields=['phone'], name='chatbot_pro_phone_0d562f_idx')],
                'unique_together': {('email',)},
            },
        ),
        migrations.CreateModel(
            name='Chat',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('message', models.TextField()),
                ('session', models.CharField(max_length=255)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('status', models.CharField(choices=[('STARTED', 'STARTED'), ('IN_PROGRESS', 'IN_PROGRESS'), ('COMPLETED', 'COMPLETED')], max_length=20)),
                ('receiver', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='receiver', to='chatbot.profile')),
                ('sender', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='sender', to='chatbot.profile')),
            ],
            options={
                'indexes': [models.Index(fields=['session'], name='chatbot_cha_session_e35dc3_idx')],
            },
        ),
    ]
